{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\jurek/.cache\\torch\\hub\\WongKinYiu_yolov7_main\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 12                -1  1         0  models.common.MP                        []                            \n",
      " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
      " 25                -1  1         0  models.common.MP                        []                            \n",
      " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 38                -1  1         0  models.common.MP                        []                            \n",
      " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
      " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
      " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 76                -1  1         0  models.common.MP                        []                            \n",
      " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
      " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 89                -1  1         0  models.common.MP                        []                            \n",
      " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
      " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
      " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
      "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
      "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
      "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
      "105   [102, 103, 104]  1    457725  models.yolo.Detect                      [80, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
      "Model Summary: 407 layers, 37620125 parameters, 37620125 gradients, 106.5 GFLOPS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from src.utils.datasets import letterbox\n",
    "from src.utils.general import non_max_suppression_kpt\n",
    "from src.utils.plots import output_to_keypoint\n",
    "import torchinfo\n",
    "\n",
    "INPUT = \"../data/20230307_143020.mp4\"  # video\n",
    "# INPUT = \"../data/video.mp4\"\n",
    "device = torch.device(\"cuda:0\")  #select device\n",
    "try:\n",
    "    model = torch.hub.load(\"WongKinYiu/yolov7\", \"yolov7\")['model']\n",
    "except:\n",
    "    pass\n",
    "model = torch.load('../ml_models/yolov7-w6-pose.pt', map_location=device)['model']\n",
    "_ = model.float().eval()\n",
    "model.\n",
    "torchinfo.summary(model, input_size=(1, 3, 960, 960))\n",
    "# if torch.cuda.is_available():\n",
    "#     model.half().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def plot_skele(im, kpts, steps, orig_shape=None):\n",
    "    skel = [[6, 7], [7, 9], [9, 11], [6, 8], [8, 10]]\n",
    "    num_kpts = len(kpts) // steps\n",
    "    r = 255\n",
    "    g = 255\n",
    "    b = 255\n",
    "    radius = 3\n",
    "    for kid in range(num_kpts):\n",
    "        if kid not in [1, 5, 6, 7, 8, 9, 10]:\n",
    "            continue\n",
    "        if kid == 1:\n",
    "            label = \"head\"\n",
    "        elif kid == 9:\n",
    "            label = \"L hand\"\n",
    "        elif kid == 10:\n",
    "            label = \"R hand\"\n",
    "        else:\n",
    "            label = str(kid)\n",
    "        x_coord, y_coord = kpts[steps * kid], kpts[steps * kid + 1]\n",
    "        cv2.circle(im, (int(x_coord), int(y_coord)), radius, (int(r), int(g), int(b)), -1)\n",
    "        cv2.putText(im, label, (int(x_coord), int(y_coord)), cv2.FONT_HERSHEY_SIMPLEX, .5, (255, 255, 255), 1,\n",
    "                    cv2.LINE_AA)\n",
    "    for sk_id, sk in enumerate(skel):\n",
    "        pos1 = (int(kpts[(sk[0] - 1) * steps]), int(kpts[(sk[0] - 1) * steps + 1]))\n",
    "        pos2 = (int(kpts[(sk[1] - 1) * steps]), int(kpts[(sk[1] - 1) * steps + 1]))\n",
    "        cv2.line(im, pos1, pos2, (int(r), int(g), int(b)), thickness=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'size'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 11\u001B[0m\n\u001B[0;32m      9\u001B[0m img \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(np\u001B[38;5;241m.\u001B[39marray([img\u001B[38;5;241m.\u001B[39mnumpy()]))\u001B[38;5;241m.\u001B[39mcuda()\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# img = img.half().to(device)\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m output, _ \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1920\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m output \u001B[38;5;241m=\u001B[39m non_max_suppression_kpt(output, \u001B[38;5;241m0.25\u001B[39m, \u001B[38;5;241m0.65\u001B[39m, nc\u001B[38;5;241m=\u001B[39mmodel\u001B[38;5;241m.\u001B[39myaml[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnc\u001B[39m\u001B[38;5;124m'\u001B[39m], nkpt\u001B[38;5;241m=\u001B[39mmodel\u001B[38;5;241m.\u001B[39myaml[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnkpt\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m     13\u001B[0m                                  kpt_label\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     14\u001B[0m output \u001B[38;5;241m=\u001B[39m output_to_keypoint(output)\n",
      "File \u001B[1;32mC:\\tools\\miniconda3\\envs\\bigdata\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "\u001B[1;31mTypeError\u001B[0m: forward() got an unexpected keyword argument 'size'"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(INPUT)\n",
    "with torch.no_grad():\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        # frame = letterbox(frame, 960, stride=64, auto=True)[0]\n",
    "        # frame = cv2.resize(frame, (960,960), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        img = transforms.ToTensor()(frame)\n",
    "        img = torch.tensor(np.array([img.numpy()])).cuda()\n",
    "        # img = img.half().to(device)\n",
    "        output, _ = model(img)\n",
    "        output = non_max_suppression_kpt(output, 0.25, 0.65, nc=model.yaml['nc'], nkpt=model.yaml['nkpt'],\n",
    "                                         kpt_label=True)\n",
    "        output = output_to_keypoint(output)\n",
    "        nimg = img[0].permute(1, 2, 0) * 255\n",
    "        nimg = nimg.cpu().numpy().astype(np.uint8)\n",
    "        nimg = cv2.cvtColor(nimg, cv2.IMREAD_COLOR)\n",
    "        # cv2.putText(nimg, f\"{output.shape[0]}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        for idx in range(output.shape[0]):\n",
    "            plot_skele(nimg, output[idx, 7:].T, 3)\n",
    "\n",
    "        cv2.imshow('image', nimg)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        # del frame, img, output, nimg\n",
    "        # torch.cuda.empty_cache()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
